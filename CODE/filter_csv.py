import os
import pandas as pd
import numpy as np
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor
from scipy.spatial import KDTree
import traceback


def filter_by_address(input_csv_folder, output_csv_folder, address_name="ì„œìš¸íŠ¹ë³„ì‹œ"):
    # type: (str, str, str) -> str
    print("=============================")
    print("===== filter_by_address =====")
    print("=============================")

    # Output folder ì´ë¦„ ì„¤ì •
    output_csv_folder = os.path.join(output_csv_folder + "/" + address_name)

    # Output folder ìƒì„±
    if not os.path.exists(output_csv_folder):
        os.makedirs(output_csv_folder)

    # MERGED_CSV í´ë” ë‚´ì˜ ëª¨ë“  CSV íŒŒì¼ ì²˜ë¦¬
    for file_name in os.listdir(input_csv_folder):
        print("Filtering by address_name -> file_name: ", file_name)
        if file_name.endswith(".csv"):
            file_path = os.path.join(input_csv_folder, file_name)

            # CSV íŒŒì¼ ì½ê¸°
            try:
                df = pd.read_csv(file_path, encoding="utf-8-sig", on_bad_lines="warn")
            except UnicodeDecodeError:
                df = pd.read_csv(file_path, encoding="cp949", on_bad_lines="warn")
            # "ì†Œì¬ì§€ì „ì²´ì£¼ì†Œ" ì—´ì—ì„œ cityì´ í¬í•¨ëœ ë°ì´í„° í•„í„°ë§
            if "ì†Œì¬ì§€ì „ì²´ì£¼ì†Œ" in df.columns:
                filtered_df = df[
                    df["ì†Œì¬ì§€ì „ì²´ì£¼ì†Œ"].str.contains(address_name, na=False)
                ]

                # í•„í„°ë§ëœ ë°ì´í„°ë¥¼ output_csv_folder ì €ì¥
                output_path = os.path.join(output_csv_folder, file_name)
                filtered_df.to_csv(output_path, index=False, encoding="utf-8-sig")

    print(
        f"Filtered data containing '{address_name}' has been saved to {output_csv_folder}."
    )
    return output_csv_folder


def filter_by_open_and_close(input_csv_folder, output_csv_folder, open_year):
    # type: (str, str, str) -> str
    print("=============================")
    print("= filter_by_open_and_close ==")
    print("=============================")

    # Output folder ì´ë¦„ ì„¤ì •
    output_csv_folder = os.path.join(output_csv_folder + "/00openat" + str(open_year))

    # Output folder ìƒì„±
    if not os.path.exists(output_csv_folder):
        os.makedirs(output_csv_folder)

    for file_name in os.listdir(input_csv_folder):
        print("filter_by_open_and_close -> file_name: ", file_name)
        # Check the number of rows in the CSV file
        file_path = os.path.join(input_csv_folder, file_name)

        # Read the CSV file
        df = pd.read_csv(file_path, encoding="utf-8-sig", on_bad_lines="warn")

        # Filter rows where "ì˜ì—…ìƒíƒœëª…" is either "íì—…" or "ì˜ì—…/ì •ìƒ"
        filtered_df = df[df["ì˜ì—…ìƒíƒœëª…"].isin(["íì—…", "ì˜ì—…/ì •ìƒ"])]

        # Filter rows where "ì¸í—ˆê°€ì¼ì" is in the year 2016
        filtered_df = filtered_df[
            filtered_df["ì¸í—ˆê°€ì¼ì"].str.split("-").str[0] == "2016"
        ]

        # ì˜ì—… ìƒíƒœëª…ì´ íì—…ì´ì§€ë§Œ íì—…ì¼ìê°€ ì—†ëŠ”ê²½ìš° ì œê±°
        filtered_df = filtered_df[
            ~(
                (filtered_df["ì˜ì—…ìƒíƒœëª…"] == "íì—…")
                & (filtered_df["íì—…ì¼ì"].isnull())
            )
        ]
        filtered_df.to_csv(
            os.path.join(output_csv_folder, file_name),
            index=False,
            encoding="utf-8-sig",
        )

    print(
        f"Filtered data containing '{"OPENAND CLOSE"}' has been saved to {output_csv_folder}."
    )
    return output_csv_folder


def add_survival_column(input_csv_folder, output_csv_folder):
    # type: (str, str) -> str
    def calculate_survival(row):
        # ê°œì—… ì´í›„ë¶€í„° ë§Œ 3ë…„ì„ ì±„ìš´ ê²½ìš°ëŠ” True (ìƒì¡´) ê·¸ë ‡ì§€ ëª»í•œ ê²½ìš°ëŠ” False (ì‚¬ë§)
        if row["ì˜ì—…ìƒíƒœëª…"] == "ì˜ì—…/ì •ìƒ":
            return True

        # íì—…í•˜ì˜€ë”ë¼ë„ 3ë…„ì´ìƒ ì˜ì—…í•œê²½ìš°ëŠ” ìƒì¡´ìœ¼ë¡œ ê°„ì£¼
        if row["ì˜ì—…ìƒíƒœëª…"] == "íì—…":
            start_date = datetime.strptime(row["ì¸í—ˆê°€ì¼ì"], "%Y-%m-%d")
            end_date = datetime.strptime(row["íì—…ì¼ì"], "%Y-%m-%d")
            survival_period = (end_date - start_date).days / 365.0

            return survival_period > 3

        return False

        # try:
        #     return (
        #         True
        #         if row["ì˜ì—…ìƒíƒœëª…"] == "ì˜ì—…/ì •ìƒ"
        #         or (
        #             row["ì˜ì—…ìƒíƒœëª…"] == "íì—…"
        #             and int(row["íì—…ì¼ì"].split("-")[0]) > 2019
        #         )
        #         else False
        #     )
        # except Exception as e:
        #     print(f"Error processing row: {row}")
        #     raise e

    print("=============================")
    print("==== add_survival_column ====")
    print("=============================")

    # Output folder ì´ë¦„ ì„¤ì •
    output_csv_folder = os.path.join(output_csv_folder + "/02survival")

    # Ensure the output directory exists
    os.makedirs(output_csv_folder, exist_ok=True)

    # Iterate through all CSV files in the input directory
    print("input_csv_folder: ", input_csv_folder)
    for file_name in os.listdir(input_csv_folder):
        print("add_survival_column -> file_name: ", file_name)
        # Check the number of rows in the CSV file
        file_path = os.path.join(input_csv_folder, file_name)

        # Read the CSV file
        df = pd.read_csv(file_path, encoding="utf-8-sig", on_bad_lines="warn")

        # Create a new column "ìƒì¡´" with 0 or 1 based on the conditions
        df["ìƒì¡´"] = df.apply(calculate_survival, axis=1)

        # Save the filtered DataFrame to the output directory
        output_path = os.path.join(output_csv_folder + "/" + file_name)
        df.to_csv(output_path, index=False)

    return output_csv_folder


def filter_small_csv_files(input_csv_folder, output_csv_folder, max_rows=50):
    # type: (str, str, int) -> str
    print("=============================")
    print("== filter_small_csv_files ===")
    print("=============================")

    # Output folder ì´ë¦„ ì„¤ì •
    output_csv_folder = os.path.join(output_csv_folder + "/01filtered")

    # Ensure the output directory exists
    os.makedirs(output_csv_folder, exist_ok=True)

    # Iterate through all CSV files in the input directory
    for file_name in os.listdir(input_csv_folder):
        print("filter_small_csv_files -> file_name: ", file_name)
        file_path = os.path.join(input_csv_folder, file_name)

        # Read the CSV file
        df = pd.read_csv(file_path, encoding="utf-8-sig", on_bad_lines="warn")

        # ë°ì´í„° 50ê°œ ì´ìƒì¸ íŒŒì¼ë§Œ ë‚¨ê¸´ë‹¤.
        if len(df) > max_rows:
            # Save the file to the output directory
            output_path = os.path.join(output_csv_folder + "/" + file_name)
            df.to_csv(output_path, index=False, encoding="utf-8-sig")

    print(
        f"CSV files with {max_rows} rows or fewer have been saved to {output_csv_folder}."
    )
    return output_csv_folder


class DistanceCalculator:
    def __init__(self, folder_path, output_folder_path, end_date):
        self.folder_path = folder_path
        self.output_folder_path = output_folder_path + "/03DISTANCE_CALCULATED"
        self.end_date = end_date

        if not os.path.exists(self.output_folder_path):
            os.makedirs(self.output_folder_path)

    # ë‚ ì§œ íŒŒì‹± í•¨ìˆ˜
    def parse_date(self, date_str):
        try:
            return datetime.strptime(date_str, "%Y-%m-%d")
        except:
            return None

    # ì˜ì—… ì‹œê¸° ë¬¸ìì—´ ìƒì„±
    def calculate_operating_period(self, df):
        operating_periods = []
        for _, row in df.iterrows():
            start_date = self.parse_date(row["ì¸í—ˆê°€ì¼ì"])
            close_date = self.parse_date(row["íì—…ì¼ì"])
            if not close_date:
                close_date = self.end_date
            operating_periods.append(f"{start_date.date()}~{close_date.date()}")
        return operating_periods

    # ê±°ë¦¬ ê³„ì‚°
    def calculate_average_distance(self, df):
        distances = []

        df = df.copy()
        df["start_date"] = df["ì˜ì—… ì‹œê¸°"].apply(
            lambda x: datetime.strptime(x.split("~")[0], "%Y-%m-%d")
        )
        df["end_date"] = df["ì˜ì—… ì‹œê¸°"].apply(
            lambda x: datetime.strptime(x.split("~")[1], "%Y-%m-%d")
        )

        # ì¢Œí‘œ ë°ì´í„°ì—ì„œ NaN ë˜ëŠ” ë¹„ì •ìƒ ê°’ ì œê±°
        df = df.dropna(subset=["ì¢Œí‘œì •ë³´x(epsg5174)", "ì¢Œí‘œì •ë³´y(epsg5174)"])
        df = df[
            np.isfinite(df["ì¢Œí‘œì •ë³´x(epsg5174)"])
            & np.isfinite(df["ì¢Œí‘œì •ë³´y(epsg5174)"])
        ]

        for idx, row in df.iterrows():
            start_date, end_date = row["start_date"], row["end_date"]
            current_location = (row["ì¢Œí‘œì •ë³´x(epsg5174)"], row["ì¢Œí‘œì •ë³´y(epsg5174)"])

            # ì›” ë‹¨ìœ„ ì‹œì  ìƒ˜í”Œë§
            dates = pd.date_range(start=start_date, end=end_date, freq="MS")

            min_distances = []

            for date in dates:
                # í˜„ì¬ ë‚ ì§œì— ì˜ì—… ì¤‘ì¸ ë‹¤ë¥¸ ì—…ì¥ í•„í„°ë§
                operating = df[
                    (df["ì‚¬ì—…ì¥ëª…"] != row["ì‚¬ì—…ì¥ëª…"])
                    & (df["start_date"] <= date)
                    & (df["end_date"] >= date)
                ]

                if len(operating) == 0:
                    continue

                # ì¢Œí‘œ ë°°ì—´ ìƒì„±
                coords = (
                    operating[["ì¢Œí‘œì •ë³´x(epsg5174)", "ì¢Œí‘œì •ë³´y(epsg5174)"]]
                    .dropna()
                    .values
                )
                tree = KDTree(coords)
                dist, _ = tree.query([current_location], k=1)
                min_distances.append(dist[0])

            avg_distance = np.mean(min_distances) if min_distances else 0
            print(" í‰ê·  ìµœê·¼ì ‘ ê±°ë¦¬:", avg_distance)
            distances.append(avg_distance)

        return df, distances

    # ê°œë³„ íŒŒì¼ ì²˜ë¦¬ í•¨ìˆ˜
    def process_file(self, file):
        try:
            print(f"ğŸ”„ ì²˜ë¦¬ ì‹œì‘ add average distance -> {file}")
            file_path = os.path.join(self.folder_path, file)
            df = pd.read_csv(file_path, encoding="utf-8-sig", on_bad_lines="warn")

            # í•„ìˆ˜ ì—´ í™•ì¸
            required_columns = {
                "ì¸í—ˆê°€ì¼ì",
                "íì—…ì¼ì",
                "ì¢Œí‘œì •ë³´x(epsg5174)",
                "ì¢Œí‘œì •ë³´y(epsg5174)",
                "ì‚¬ì—…ì¥ëª…",
            }

            if not required_columns.issubset(df.columns):
                print(f"âš ï¸ í•„ìˆ˜ ì—´ ëˆ„ë½ìœ¼ë¡œ ìŠ¤í‚µ: {file}")
                missing_columns = required_columns - set(df.columns)
                print(f"ëˆ„ë½ëœ ì—´: {missing_columns}")
                return

            # ì˜ì—… ì‹œê¸° ê³„ì‚°
            df["ì˜ì—… ì‹œê¸°"] = self.calculate_operating_period(df)

            # í‰ê·  ìµœê·¼ì ‘ ê±°ë¦¬ ê³„ì‚°
            df, distances = self.calculate_average_distance(df)
            df["ë™ì¼ì—…ì¢… ìµœê·¼ì ‘ê±°ë¦¬ì˜ í‰ê· "] = distances
            # ì €ì¥
            output_path = os.path.join(self.output_folder_path, file)
            df.to_csv(output_path, index=False)
            print(f"âœ… ì™„ë£Œ: {file}")

        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {file}")
            traceback.print_exc()

    # ëª¨ë“  íŒŒì¼ ì²˜ë¦¬ í•¨ìˆ˜
    def process_all_files(self):
        print("=============================")
        print("=== add average distance ====")
        print("=============================")

        csv_files = [f for f in os.listdir(self.folder_path) if f.endswith(".csv")]

        with ThreadPoolExecutor() as executor:
            executor.map(self.process_file, csv_files)

        print("ğŸ‰ ëª¨ë“  íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ!")


if __name__ == "__main__":
    INPUT_FOLDER = "C:/Users/bsh96/Documents/GitHub/spring_UDIK/DATA/LOCALDATA_ALL_CSV"
    OUTPUT_FOLDER = (
        "C:/Users/bsh96/Documents/GitHub/spring_UDIK/DATA/LOCALDATA_FILTERED_CSV"
    )

    # # ì„œìš¸íŠ¹ë³„ì‹œ ê°•ë‚¨êµ¬ ë°ì´í„°ë§Œ í•„í„°ë§
    # output_csv_folder = filter_by_address(
    #     INPUT_FOLDER, OUTPUT_FOLDER, address_name="ì„œìš¸íŠ¹ë³„ì‹œ ê°•ë‚¨êµ¬"
    # )

    # # ê°œì—…ì—°ë„ê°€ 2016ë…„ë„ì´ë©° ë°ì´í„°ë§Œ í•„í„°ë§ (ì˜ì—…ì¤‘/íì—… ì´ì™¸ì˜ ìƒíƒœëŠ” ëª¨ë‘ ì œê±°)
    # output_csv_folder = filter_by_open_and_close(
    #     output_csv_folder, OUTPUT_FOLDER, open_year=2016
    # )

    # # ë°ì´í„°ê°€ 50ê°œ ì´í•˜ì¸ csvíŒŒì¼ì€ ì œì™¸.
    # output_csv_folder = filter_small_csv_files(
    #     output_csv_folder,
    #     OUTPUT_FOLDER,
    #     max_rows=50,
    # )

    output_csv_folder = "C:/Users/bsh96/Documents/GitHub/spring_UDIK/DATA/LOCALDATA_FILTERED_CSV/01filtered"

    # ìƒì¡´ column ì¶”ê°€
    output_csv_folder = add_survival_column(
        output_csv_folder,
        OUTPUT_FOLDER,
    )

    # ìµœê·¼ì ‘ ê±°ë¦¬ ê³„ì‚°
    calculator = DistanceCalculator(
        output_csv_folder, OUTPUT_FOLDER, end_date=datetime(2019, 12, 31)
    )
    calculator.process_all_files()

    print("All filtering and processing tasks completed successfully.")
